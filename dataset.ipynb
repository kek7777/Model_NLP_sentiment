{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This notebook used for preporation data to NLP modeling.\n",
    " Proceses of Tokenization, Stemming, Lemmatization, Handling text (Remove HTML Tag, URLs, Emojies and other) are here.   \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re                                              # Import Regular Expression (remove HTML tags)\n",
    "import string                                          # Import Punctuation \n",
    "from textblob import TextBlob                          # Import this Library to Handle the Spelling Issue\n",
    "import nltk\n",
    "from nltk.corpus import stopwords                      #  NLTK library to remove Stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji                                           # for translating symbol to text\n",
    "import spacy                                           # for tokenization\n",
    "from nltk.stem.porter import PorterStemmer             # for stemming\n",
    "#nltk.download('all')                                   # for  working with NLTL function, after the first start should pick #nltk.download('all') \n",
    "from sklearn.model_selection import train_test_split\n",
    "from chat_words import chat_word                       # for translate slang of charts to text\n",
    "from autocorrect import Speller                        # for Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Admin\\WORK\\Project_CV\\Model_NLP_sentiment\\data\\IMDB Dataset.csv')    # insert path to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)                                                # check dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49975,)\n",
      "(25,)\n"
     ]
    }
   ],
   "source": [
    "#Access the corpus and target variables\n",
    "x = df.review\n",
    "y = df.sentiment                                                                            \n",
    "\n",
    "# train test splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.0005, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose items for preprocessing: True or False\n",
    "\n",
    "lower = True                           # LoweCasing Text\n",
    "remove_html = True                     # Remove HTML Tag\n",
    "remove_url = True                       # Remove URLs\n",
    "remove_punc = True                     # Remove punctuation\n",
    "change_chat = True                     # Handling chat's words to words\n",
    "spell_cor = True                       # Spelling Correction\n",
    "remove_stopword = True                 # Remove StopWords\n",
    "remove_emoji = True                  # Handling Emojies to words\n",
    "use_stemm = False                       # Apply Stemming\n",
    "use_lemm = True                        # Apply Lemmatization\n",
    "use_token = True                        # Apply Tokenization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing\n",
    "def preprocessing (text):\n",
    "        \n",
    "    if lower:                                                        # LoweCasing Text\n",
    "        text = text.lower()\n",
    "                                            \n",
    "    if remove_html:\n",
    "        pattern_1 = re.compile('<.*?>')                              # constant using one regular expression\n",
    "        text = re.sub(pattern_1, r'', text)                          # Remove HTML Tags (changes ('<.*?>') to gap \" \")\n",
    "\n",
    "    if remove_url:\n",
    "        pattern_2 = re.compile(r'https?://\\S+|www\\.\\S+')             #  Remove URLs from Text or Whole Corpus.\n",
    "        text = pattern_2.sub(r'', text)\n",
    "\n",
    "    if remove_punc:\n",
    "        punc = string.punctuation                                    # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', punc))\n",
    "\n",
    "    if change_chat:\n",
    "        new_text = []                                                 # changes chat's words to text       \n",
    "        for i in text.split():\n",
    "            if i.upper() in chat_word:\n",
    "                new_text.append(chat_word[i.upper()])\n",
    "            else:\n",
    "                new_text.append(i)\n",
    "        text = \" \".join(new_text)\n",
    "        new_text.clear()\n",
    "\n",
    "    if spell_cor:\n",
    "        spell = Speller(lang='en')                                    # Spelling Correction\n",
    "        text = spell(text)\n",
    "\n",
    "    if remove_stopword:\n",
    "        stopword = stopwords.words('english')                          # Handling StopWords\n",
    "        for word in text.split():\n",
    "            if word in stopword:\n",
    "                new_text.append('')\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        pattern_3 = new_text[:]\n",
    "        text = \" \".join(pattern_3)\n",
    "\n",
    "    if remove_emoji:\n",
    "        text = emoji.demojize(text)                                   # Handling Emojies \n",
    "\n",
    "    \n",
    "    if use_stemm:\n",
    "        stemmer = PorterStemmer()                                     # Stemming\n",
    "        text = \" \".join([stemmer.stem(word)\n",
    "                  for word in text.split()])\n",
    "                            \n",
    "        \n",
    "    if use_lemm:\n",
    "        lemmatizer = WordNetLemmatizer()                              #Lemmatization\n",
    "        words = nltk.word_tokenize(text)\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        text = ' '.join(lemmatized_words)\n",
    "\n",
    "\n",
    "    if use_token:\n",
    "        nlp = spacy.load('en_core_web_sm')                            # the English language model 'en_core_web_sm'\n",
    "        text = nlp(text)                                              # cmd:  python -m spacy download en_core_web_sm\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying function for preprocessing\n",
    "\n",
    "# X_trainn = X_train.apply(preprocessing)\n",
    "X_testt = X_test.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @lapcat need to send 'em to my accountant tomo...\n",
       "1    <html><body><p> Movie 1</p><p> Actor - Aamir K...\n",
       "2    Check out my notebook https://www.kaggle.com/c...\n",
       "3                                  IMHO he is the best\n",
       "4             FYI Islamabad is the capital of Pakistan\n",
       "5    ceertain conditionas duriing seveal ggeneratio...\n",
       "6    probably my all-time favorite movie, a story o...\n",
       "7                            Loved the movie. It was ðŸ˜˜\n",
       "8                            walk walks walking walked\n",
       "9    He was running and eating at same time. He has...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This block for checking  def Proprocessing\n",
    "\n",
    "check_data = {\n",
    "    \"review\": [\"@lapcat need to send 'em to my accountant tomorrow. oddly, i wasn't even referring to my taxes. those are supporting evidence, though. \",\n",
    "                \"<html><body><p> Movie 1</p><p> Actor - Aamir Khan</p><p> Click here to <a href='http://google.com'>download</a></p></body></html>\",\n",
    "                 'Check out my notebook https://www.kaggle.com/campusx/notebook8223fc1', 'IMHO he is the best', 'FYI Islamabad is the capital of Pakistan',\n",
    "                 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner', 'probably my all-time favorite movie, a story of selflessness,'\n",
    "                 ' sacrifice and dedication to a noble cause', \"Loved the movie. It was ðŸ˜˜\", \"walk walks walking walked\",\n",
    "                 \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "]\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_check = pd.DataFrame(check_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "prov = df_check['review']\n",
    "prov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (lancet, need, send, em, account, tomorrow, od...\n",
       "1    (htmlbodyp, movi, 1pp, actor, amir, khan, clic...\n",
       "2                                    (check, notebook)\n",
       "3            (in, my, honest, /, humbl, opinion, best)\n",
       "4      (for, your, inform, islamabad, capit, pakistan)\n",
       "5       (certain, condit, sever, gener, modifi, mater)\n",
       "6    (probabl, alltim, favorit, movi, stori, selfle...\n",
       "7              (love, movi, :, face_blowing_a_kiss, :)\n",
       "8                             (walk, walk, walk, walk)\n",
       "9    (run, eat, tear, eye, bad, habit, swim, play, ...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prov_check = prov.apply(preprocessing)\n",
    "prov_check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
