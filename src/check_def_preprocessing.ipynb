{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93371165",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This note allows to check properly work def preprocessing'''\n",
    "import pandas as pd\n",
    "import re                                              # Import Regular Expression (remove HTML tags)\n",
    "import string                                          # Import Punctuation \n",
    "from textblob import TextBlob                          # Import this Library to Handle the Spelling Issue\n",
    "import nltk\n",
    "from nltk.corpus import stopwords                      #  NLTK library to remove Stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji                                           # for translating symbol to text\n",
    "import spacy                                           # for tokenization\n",
    "import spacy.cli\n",
    "# spacy.cli.download(\"en_core_web_sm\")                 # for  working with spacy, after the first start should pick  # spacy.cli.download(\"en_core_web_lg\")\n",
    "from nltk.stem.porter import PorterStemmer             # for stemming\n",
    "# nltk.download('all')                                   # for  working with NLTL function, after the first start should pick #nltk.download('all') \n",
    "from sklearn.model_selection import train_test_split\n",
    "from chat_words import chat_word                       # for translate slang of charts to text\n",
    "from autocorrect import Speller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e1b3112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @lapcat need to send 'em to my accountant tomo...\n",
       "1    <html><body><p> Movie 1</p><p> Actor - Aamir K...\n",
       "2    Check out my notebook https://www.kaggle.com/c...\n",
       "3                                  IMHO he is the best\n",
       "4             FYI Islamabad is the capital of Pakistan\n",
       "5    ceertain conditionas duriing seveal ggeneratio...\n",
       "6    probably my all-time favorite movie, a story o...\n",
       "7                            Loved the movie. It was ðŸ˜˜\n",
       "8                            walk walks walking walked\n",
       "9    He was running and eating at same time. He has...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This block for checking  def Preprocessing\n",
    "\n",
    "check_data = {\n",
    "    \"review\": [\"@lapcat need to send 'em to my accountant tomorrow. oddly, i wasn't even referring to my taxes. those are supporting evidence, though. \",\n",
    "                \"<html><body><p> Movie 1</p><p> Actor - Aamir Khan</p><p> Click here to <a href='http://google.com'>download</a></p></body></html>\",\n",
    "                 'Check out my notebook https://www.kaggle.com/campusx/notebook8223fc1', 'IMHO he is the best', 'FYI Islamabad is the capital of Pakistan',\n",
    "                 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner', 'probably my all-time favorite movie, a story of selflessness,'\n",
    "                 ' sacrifice and dedication to a noble cause', \"Loved the movie. It was ðŸ˜˜\", \"walk walks walking walked\",\n",
    "                 \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "]\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_check = pd.DataFrame(check_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "prov = df_check['review']\n",
    "prov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b8d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose items for preprocessing: True or False\n",
    "\n",
    "lower = True                           # LoweCasing Text\n",
    "remove_html = True                     # Remove HTML Tag\n",
    "remove_url = True                       # Remove URLs\n",
    "remove_punc = True                     # Remove punctuation\n",
    "change_chat = True                     # Handling chat's words to words\n",
    "spell_cor = True                       # Spelling Correction\n",
    "remove_stopword = True                 # Remove StopWords\n",
    "remove_emoji = True                  # Handling Emojies to words\n",
    "use_stemm = False                       # Apply Stemming\n",
    "use_lemm = True                        # Apply Lemmatization\n",
    "use_token = True                       # Apply Tokenization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62bfa8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing\n",
    "def preprocessing (text):\n",
    "        \n",
    "    if lower:                                                        # LoweCasing Text\n",
    "        text = text.lower()\n",
    "                                            \n",
    "    if remove_html:\n",
    "        pattern_1 = re.compile('<.*?>')                              # constant using one regular expression\n",
    "        text = re.sub(pattern_1, r'', text)                          # Remove HTML Tags (changes ('<.*?>') to gap \" \")\n",
    "\n",
    "    if remove_url:\n",
    "        pattern_2 = re.compile(r'https?://\\S+|www\\.\\S+')             #  Remove URLs from Text or Whole Corpus.\n",
    "        text = pattern_2.sub(r'', text)\n",
    "\n",
    "    if remove_punc:\n",
    "        punc = string.punctuation                                    # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', punc))\n",
    "\n",
    "    if change_chat:\n",
    "        new_text = []                                                 # changes chat's words to text       \n",
    "        for i in text.split():\n",
    "            if i.upper() in chat_word:\n",
    "                new_text.append(chat_word[i.upper()])\n",
    "            else:\n",
    "                new_text.append(i)\n",
    "        text = \" \".join(new_text)\n",
    "        new_text.clear()\n",
    "\n",
    "    if spell_cor:\n",
    "        spell = Speller(lang='en')                                    # Spelling Correction\n",
    "        text = spell(text)\n",
    "\n",
    "    if remove_stopword:\n",
    "        stopword = stopwords.words('english')                          # Handling StopWords\n",
    "        for word in text.split():\n",
    "            if word in stopword:\n",
    "                new_text.append('')\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        pattern_3 = new_text[:]\n",
    "        text = \" \".join(pattern_3)\n",
    "\n",
    "    if remove_emoji:\n",
    "        text = emoji.demojize(text)                                   # Handling Emojies \n",
    "\n",
    "    \n",
    "    if use_stemm:\n",
    "        stemmer = PorterStemmer()                                     # Stemming\n",
    "        text = \" \".join([stemmer.stem(word)\n",
    "                  for word in text.split()])\n",
    "                            \n",
    "        \n",
    "    if use_lemm:\n",
    "        lemmatizer = WordNetLemmatizer()                              #Lemmatization\n",
    "        words = nltk.word_tokenize(text)\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        text = ' '.join(lemmatized_words)\n",
    "\n",
    "\n",
    "    if use_token:\n",
    "        nlp = spacy.load('en_core_web_sm')                            # the English language model 'en_core_web_sm'\n",
    "        text = nlp(text)                                              # cmd:  python -m spacy download en_core_web_sm\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e5d4f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (lancet, need, send, em, accountant, tomorrow,...\n",
       "1       (movie, 1, actor, amir, khan, click, download)\n",
       "2                                    (check, notebook)\n",
       "3           (In, My, Honest, /, Humble, Opinion, best)\n",
       "4    (For, Your, Information, islamabad, capital, p...\n",
       "5    (certain, condition, several, generation, modi...\n",
       "6    (probably, alltime, favorite, movie, story, se...\n",
       "7            (loved, movie, :, face_blowing_a_kiss, :)\n",
       "8                        (walk, walk, walking, walked)\n",
       "9    (running, eating, Tears, eye, bad, habit, swim...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prov_check = prov.apply(preprocessing)\n",
    "prov_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102dce0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_sent_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
