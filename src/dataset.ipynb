{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\WORK\\Project_CV\\Model_NLP_sentiment\\NLP_sent_venv\\lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\Admin\\WORK\\Project_CV\\Model_NLP_sentiment\\NLP_sent_venv\\lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This notebook used for preporation data to NLP modeling.\n",
    " Proceses of Tokenization, Stemming, Lemmatization, Handling text (Remove HTML Tag, URLs, Emojies and other) are here.   \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re                                              # Import Regular Expression (remove HTML tags)\n",
    "import string                                          # Import Punctuation \n",
    "from textblob import TextBlob                          # Import this Library to Handle the Spelling Issue\n",
    "import nltk\n",
    "from nltk.corpus import stopwords                      #  NLTK library to remove Stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji                                           # for translating symbol to text\n",
    "import spacy                                           # for tokenization\n",
    "import spacy.cli\n",
    "# spacy.cli.download(\"en_core_web_sm\")                 # for  working with spacy, after the first start should pick  # spacy.cli.download(\"en_core_web_lg\")\n",
    "from nltk.stem.porter import PorterStemmer             # for stemming\n",
    "# nltk.download('all')                                   # for  working with NLTL function, after the first start should pick #nltk.download('all') \n",
    "from sklearn.model_selection import train_test_split\n",
    "from chat_words import chat_word                       # for translate slang of charts to text\n",
    "from autocorrect import Speller                        # for Spelling Correction\n",
    "from collections import Counter, OrderedDict           # for definition of unique words (tokens) in dataframe\n",
    "from torchtext.vocab import vocab  \n",
    "from tqdm import tqdm                                   # progressbar\n",
    "tqdm.pandas() \n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Admin\\WORK\\Project_CV\\Model_NLP_sentiment\\data\\IMDB Dataset.csv')    # insert path to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)                                                # check dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  label\n",
       "0  One of the other reviewers has mentioned that ...  positive      1\n",
       "1  A wonderful little production. <br /><br />The...  positive      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # transform sentiment  into the number labels\n",
    "# def transform_label(label):\n",
    "#     return 1 if label == 'positive' else 0\n",
    "\n",
    "# df['label'] = df['sentiment'].apply(transform_label)\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49975,)\n",
      "(25,)\n",
      "(49975,)\n",
      "(25,)\n"
     ]
    }
   ],
   "source": [
    "# #Access the corpus and target variables\n",
    "# x = df.review\n",
    "# y = df.label                                                                            \n",
    "\n",
    "# # train test splitting\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.0005, random_state=0)\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose items for preprocessing: True or False\n",
    "\n",
    "lower = True                           # LoweCasing Text\n",
    "remove_html = True                     # Remove HTML Tag\n",
    "remove_url = True                       # Remove URLs\n",
    "remove_punc = True                     # Remove punctuation\n",
    "change_chat = True                     # Handling chat's words to words\n",
    "spell_cor = True                       # Spelling Correction\n",
    "remove_stopword = True                 # Remove StopWords\n",
    "remove_emoji = True                  # Handling Emojies to words\n",
    "use_stemm = False                       # Apply Stemming\n",
    "use_lemm = True                        # Apply Lemmatization\n",
    "use_token = True                       # Apply Tokenization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing\n",
    "def preprocessing (text):\n",
    "        \n",
    "    if lower:                                                        # LoweCasing Text\n",
    "        text = text.lower()\n",
    "                                            \n",
    "    if remove_html:\n",
    "        pattern_1 = re.compile('<.*?>')                              # constant using one regular expression\n",
    "        text = re.sub(pattern_1, r'', text)                          # Remove HTML Tags (changes ('<.*?>') to gap \" \")\n",
    "\n",
    "    if remove_url:\n",
    "        pattern_2 = re.compile(r'https?://\\S+|www\\.\\S+')             #  Remove URLs from Text or Whole Corpus.\n",
    "        text = pattern_2.sub(r'', text)\n",
    "\n",
    "    if remove_punc:\n",
    "        punc = string.punctuation                                    # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', punc))\n",
    "\n",
    "    if change_chat:\n",
    "        new_text = []                                                 # changes chat's words to text       \n",
    "        for i in text.split():\n",
    "            if i.upper() in chat_word:\n",
    "                new_text.append(chat_word[i.upper()])\n",
    "            else:\n",
    "                new_text.append(i)\n",
    "        text = \" \".join(new_text)\n",
    "        new_text.clear()\n",
    "\n",
    "    if spell_cor:\n",
    "        spell = Speller(lang='en')                                    # Spelling Correction\n",
    "        text = spell(text)\n",
    "\n",
    "    if remove_stopword:\n",
    "        stopword = stopwords.words('english')                          # Handling StopWords\n",
    "        for word in text.split():\n",
    "            if word in stopword:\n",
    "                new_text.append('')\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        pattern_3 = new_text[:]\n",
    "        text = \" \".join(pattern_3)\n",
    "\n",
    "    if remove_emoji:\n",
    "        text = emoji.demojize(text)                                   # Handling Emojies \n",
    "\n",
    "    \n",
    "    if use_stemm:\n",
    "        stemmer = PorterStemmer()                                     # Stemming\n",
    "        text = \" \".join([stemmer.stem(word)\n",
    "                  for word in text.split()])\n",
    "                            \n",
    "        \n",
    "    if use_lemm:\n",
    "        lemmatizer = WordNetLemmatizer()                              #Lemmatization\n",
    "        words = nltk.word_tokenize(text)\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        text = ' '.join(lemmatized_words)\n",
    "\n",
    "\n",
    "    if use_token:\n",
    "        nlp = spacy.load('en_core_web_sm')                            # the English language model 'en_core_web_sm'\n",
    "        text = nlp(text)                                              \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment\n",
       "0   One of the other reviewers has mentioned that ...  positive\n",
       "1   A wonderful little production. <br /><br />The...  positive\n",
       "2   I thought this was a wonderful way to spend ti...  positive\n",
       "3   Basically there's a family where a little boy ...  negative\n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5   Probably my all-time favorite movie, a story o...  positive\n",
       "6   I sure would like to see a resurrection of a u...  positive\n",
       "7   This show was an amazing, fresh & innovative i...  negative\n",
       "8   Encouraged by the positive comments about this...  negative\n",
       "9   If you like original gut wrenching laughter yo...  positive\n",
       "10  Phil the Alien is one of those quirky films wh...  negative"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_new = df.loc[0:10]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (one, reviewer, mentioned, watching, 1, oz, ep...\n",
       "1     (wonderful, little, production, filming, techn...\n",
       "2     (thought, wonderful, way, spend, Tears, eye, h...\n",
       "3     (basically, there, family, little, boy, jake, ...\n",
       "4     (better, matter, love, Tears, eye, money, visu...\n",
       "5     (probably, alltime, favorite, movie, story, se...\n",
       "6     (sure, would, like, see, resurrection, dated, ...\n",
       "7     (show, amazing, fresh, innovative, idea, 70, f...\n",
       "8     (encouraged, positive, comment, film, looking,...\n",
       "9     (like, original, gut, reaching, laughter, like...\n",
       "10    (phil, alien, one, quirky, film, humour, based...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Applying function for preprocessing\n",
    "\n",
    "# X_trainn = X_train.apply(preprocessing)\n",
    "# x_testt = x_test.apply(preprocessing)\n",
    "# x_testt.head(2)\n",
    "\n",
    "df_new = df_new['review'].apply(preprocessing) \n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching',\n",
       " 'just',\n",
       " '1',\n",
       " 'Oz',\n",
       " 'episode',\n",
       " \"you'll\",\n",
       " 'be',\n",
       " 'hooked.',\n",
       " 'They',\n",
       " 'are',\n",
       " 'right,']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #get all processed reviews\n",
    "reviews = df.review.values\n",
    "# merge into single variable, separated by whitespaces\n",
    "words = ' '.join(reviews)\n",
    "# obtain list of words\n",
    "words = words.split()\n",
    "\n",
    "# check our list\n",
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabulary\n",
    "counter = Counter(words)\n",
    "vocab = sorted(counter, key=counter.get, reverse=True)\n",
    "int2word = dict(enumerate(vocab, 1))\n",
    "int2word[0] = '<PAD>'\n",
    "word2int = {word: id for id, word in int2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:01<00:00, 29831.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[317, 4, 1, 79, 2282]\n",
      "[130, 436, 110, 2631, 102]\n",
      "[8, 196, 10, 13, 2]\n",
      "[5357, 306, 2, 291, 108]\n",
      "[169881, 53939, 10359, 7, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# encode words\n",
    "reviews_enc = [[word2int[word] for word in review.split()] for review in tqdm(reviews)]\n",
    "\n",
    "# print first-10 words of first 5 reviews\n",
    "for i in range(5):\n",
    "    print(reviews_enc[i][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11557847\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @lapcat need to send 'em to my accountant tomo...\n",
       "1    <html><body><p> Movie 1</p><p> Actor - Aamir K...\n",
       "2    Check out my notebook https://www.kaggle.com/c...\n",
       "3                                  IMHO he is the best\n",
       "4             FYI Islamabad is the capital of Pakistan\n",
       "5    ceertain conditionas duriing seveal ggeneratio...\n",
       "6    probably my all-time favorite movie, a story o...\n",
       "7                            Loved the movie. It was ðŸ˜˜\n",
       "8                            walk walks walking walked\n",
       "9    He was running and eating at same time. He has...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This block for checking  def Proprocessing\n",
    "\n",
    "check_data = {\n",
    "    \"review\": [\"@lapcat need to send 'em to my accountant tomorrow. oddly, i wasn't even referring to my taxes. those are supporting evidence, though. \",\n",
    "                \"<html><body><p> Movie 1</p><p> Actor - Aamir Khan</p><p> Click here to <a href='http://google.com'>download</a></p></body></html>\",\n",
    "                 'Check out my notebook https://www.kaggle.com/campusx/notebook8223fc1', 'IMHO he is the best', 'FYI Islamabad is the capital of Pakistan',\n",
    "                 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner', 'probably my all-time favorite movie, a story of selflessness,'\n",
    "                 ' sacrifice and dedication to a noble cause', \"Loved the movie. It was ðŸ˜˜\", \"walk walks walking walked\",\n",
    "                 \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "]\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_check = pd.DataFrame(check_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "prov = df_check['review']\n",
    "prov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (lancet, need, send, em, accountant, tomorrow,...\n",
       "1       (movie, 1, actor, amir, khan, click, download)\n",
       "2                                    (check, notebook)\n",
       "3           (In, My, Honest, /, Humble, Opinion, best)\n",
       "4    (For, Your, Information, islamabad, capital, p...\n",
       "5    (certain, condition, several, generation, modi...\n",
       "6    (probably, alltime, favorite, movie, story, se...\n",
       "7            (loved, movie, :, face_blowing_a_kiss, :)\n",
       "8                        (walk, walk, walking, walked)\n",
       "9    (running, eating, Tears, eye, bad, habit, swim...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prov_check = prov.apply(preprocessing)\n",
    "prov_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all processed r\n",
    "# Definition of unique words (tokens) in dataframe\n",
    "\n",
    "token_counts = Counter()\n",
    "for word in x_testt:\n",
    "    token_counts.update(word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 2520\n"
     ]
    }
   ],
   "source": [
    "print('Dictionary size:', len(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sorted_by_freg_tuples = sorted (token_counts.items(), key=lambda x: x[1], reverse = True)\n",
    "ordered_dict = OrderedDict(sorted_by_freg_tuples)\n",
    "vocab = vocab(ordered_dict)\n",
    "vocab.insert_token('<pad>', 0)\n",
    "vocab.insert_token('<unk>', 1)\n",
    "vocab.set_default_index(1)\n",
    "# print([vocab[token] for token in ['Hot','run'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_testt))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_text2 \u001b[38;5;241m=\u001b[39m \u001b[43mx_testt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m11841\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# get all processed reviews\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# merge into single variable, separated by whitespaces\u001b[39;00m\n\u001b[0;32m      6\u001b[0m all_text2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(all_text2)     \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "all_text2 = x_testt[11841].tolist()\n",
    "\n",
    "# get all processed reviews\n",
    "\n",
    "# merge into single variable, separated by whitespaces\n",
    "all_text2 = ' '.join(all_text2)     \n",
    "# obtain list of words\n",
    "words = all_text2.split()\n",
    "\n",
    "# check our list\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = 20000\n",
    "TEXT = torchtext.legacy.data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_sent_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
